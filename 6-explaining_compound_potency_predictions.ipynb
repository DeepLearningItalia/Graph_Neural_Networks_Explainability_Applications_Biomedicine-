{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Author: Andrea Mastropietro © All rights reserved\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import Linear, GraphConv, global_add_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import create_edge_index, ChemicalDataset \n",
    "from src.edgeshaper import Edgeshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Working on device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10gs</th>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11gs</th>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13gs</th>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16pk</th>\n",
       "      <td>5.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184l</th>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      affinity\n",
       "10gs      6.40\n",
       "11gs      5.82\n",
       "13gs      4.62\n",
       "16pk      5.22\n",
       "184l      4.72"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af78a488895c4594abf06e3aa815cc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a480069ca244ae7b666465f866ecbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7f801f3aa741f9be9d283b319f97a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_PATH = 'data/interaction_affinity_data/'\n",
    "interaction_affinities = None\n",
    "\n",
    "with open(DATA_PATH + 'interaction_affinities.json', 'r') as fp:\n",
    "    interaction_affinities = json.load(fp)\n",
    "\n",
    "affinities_df = pd.DataFrame.from_dict(interaction_affinities, orient='index', columns=['affinity'])\n",
    "\n",
    "display(affinities_df.head())\n",
    "\n",
    "affinities_df = affinities_df.sort_values(by = \"affinity\", ascending=True)\n",
    "interaction_affinities = affinities_df.to_dict(orient='index')\n",
    "\n",
    "descriptors_interaction_dict = None\n",
    "num_node_features = 0\n",
    "\n",
    "descriptors_interaction_dict = {}\n",
    "descriptors_interaction_dict[\"CA\"] = [1, 0, 0, 0, 0, 0, 0, 0]\n",
    "descriptors_interaction_dict[\"NZ\"] = [0, 1, 0, 0, 0, 0, 0, 0]\n",
    "descriptors_interaction_dict[\"N\"] = [0, 0, 1, 0, 0, 0, 0, 0]\n",
    "descriptors_interaction_dict[\"OG\"] = [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "descriptors_interaction_dict[\"O\"] = [0, 0, 0, 0, 1, 0, 0, 0]\n",
    "descriptors_interaction_dict[\"CZ\"] = [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "descriptors_interaction_dict[\"OD1\"] = [0, 0, 0, 0, 0, 0, 1, 0]\n",
    "descriptors_interaction_dict[\"ZN\"] = [0, 0, 0, 0, 0, 0, 0, 1]\n",
    "\n",
    "num_node_features = len(descriptors_interaction_dict[\"CA\"])\n",
    "\n",
    "def generate_pli_dataset_dict(data_path):\n",
    "\n",
    "    directory = os.fsencode(data_path)\n",
    "\n",
    "    dataset_dict = {}\n",
    "    dirs = os.listdir(directory)\n",
    "    for file in tqdm(dirs):\n",
    "        interaction_name = os.fsdecode(file)\n",
    "\n",
    "        if interaction_name in interaction_affinities:\n",
    "            if os.path.isdir(data_path + interaction_name):\n",
    "                dataset_dict[interaction_name] = {}\n",
    "                G = None\n",
    "                with open(data_path + interaction_name + \"/\" + interaction_name + \"_interaction_graph.json\", 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    G = nx.Graph()\n",
    "\n",
    "                    for node in data['nodes']:\n",
    "                        G.add_node(node[\"id\"], atom_type=node[\"attype\"], origin=node[\"pl\"]) \n",
    "\n",
    "                    for edge in data['edges']:\n",
    "                        if edge[\"id1\"] != None and edge[\"id2\"] != None:\n",
    "                            G.add_edge(edge[\"id1\"], edge[\"id2\"], weight= float(edge[\"length\"]))\n",
    "                            \n",
    "\n",
    "                    for node in data['nodes']:\n",
    "                        nx.set_node_attributes(G, {node[\"id\"]: node[\"attype\"]}, \"atom_type\")\n",
    "                        nx.set_node_attributes(G, {node[\"id\"]: node[\"pl\"]}, \"origin\")\n",
    "\n",
    "                    \n",
    "                    \n",
    "                dataset_dict[interaction_name][\"networkx_graph\"] = G\n",
    "                edge_index, edge_weight = create_edge_index(G, weighted=True)\n",
    "\n",
    "                dataset_dict[interaction_name][\"edge_index\"] = edge_index\n",
    "                dataset_dict[interaction_name][\"edge_weight\"] = edge_weight\n",
    "                \n",
    "\n",
    "                num_nodes = G.number_of_nodes()\n",
    "                \n",
    "                \n",
    "                \n",
    "                dataset_dict[interaction_name][\"x\"] = torch.zeros((num_nodes, num_node_features), dtype=torch.float)\n",
    "                for node in G.nodes:\n",
    "                    dataset_dict[interaction_name][\"x\"][node] = torch.tensor(descriptors_interaction_dict[G.nodes[node][\"atom_type\"]], dtype=torch.float)\n",
    "                    \n",
    "                ## gather label\n",
    "                dataset_dict[interaction_name][\"y\"] = torch.FloatTensor([interaction_affinities[interaction_name][\"affinity\"]])\n",
    "\n",
    "    \n",
    "    return dataset_dict\n",
    "\n",
    "pli_dataset_dict = generate_pli_dataset_dict(DATA_PATH + \"/dataset/\")\n",
    "\n",
    "first_level = [pli_dataset_dict[key][\"edge_weight\"] for key in pli_dataset_dict]\n",
    "second_level = [item for sublist in first_level for item in sublist]\n",
    "\n",
    "transformer = RobustScaler().fit(np.array(second_level).reshape(-1, 1))\n",
    "\n",
    "for key in tqdm(pli_dataset_dict):\n",
    "    scaled_weights = transformer.transform(np.array(pli_dataset_dict[key][\"edge_weight\"]).reshape(-1, 1))\n",
    "    scaled_weights = [x[0] for x in scaled_weights]\n",
    "    pli_dataset_dict[key][\"edge_weight\"] = torch.FloatTensor(scaled_weights)\n",
    "\n",
    "data_list = []\n",
    "EDGE_WEIGHT = True\n",
    "for interaction_name in tqdm(pli_dataset_dict):\n",
    "    edge_weight_sample = None\n",
    "    if EDGE_WEIGHT:\n",
    "        edge_weight_sample = pli_dataset_dict[interaction_name][\"edge_weight\"]\n",
    "    data_list.append(Data(x = pli_dataset_dict[interaction_name][\"x\"], edge_index = pli_dataset_dict[interaction_name][\"edge_index\"], edge_weight = edge_weight_sample, y = pli_dataset_dict[interaction_name][\"y\"], networkx_graph = pli_dataset_dict[interaction_name][\"networkx_graph\"], interaction_name = interaction_name))\n",
    "\n",
    "dataset = ChemicalDataset(\".\", data_list = data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_out_interactions = []\n",
    "\n",
    "with open(DATA_PATH + \"data_splits/hold_out_set.csv\", 'r') as f:\n",
    "    hold_out_interactions = f.readlines()\n",
    "\n",
    "hold_out_interactions = [interaction.strip() for interaction in hold_out_interactions]\n",
    "\n",
    "hold_out_data = [dataset[i] for i in range(len(dataset)) if dataset[i].interaction_name in hold_out_interactions]\n",
    "rng = np.random.default_rng(seed = SEED)\n",
    "rng.shuffle(hold_out_data)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "hold_out_loader = DataLoader(hold_out_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GC_GNN(torch.nn.Module):\n",
    "    def __init__(self, node_features_dim, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(node_features_dim, hidden_channels, aggr='max')\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels, aggr='max')\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels, aggr='max')\n",
    "        self.conv4 = GraphConv(hidden_channels, hidden_channels, aggr='max')\n",
    "        self.conv5 = GraphConv(hidden_channels, hidden_channels, aggr='max')\n",
    "        self.conv6 = GraphConv(hidden_channels, hidden_channels, aggr='max')\n",
    "        self.conv7 = GraphConv(hidden_channels, hidden_channels, aggr='max')\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_weight = None):\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight = edge_weight))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight = edge_weight))\n",
    "        x = F.relu(self.conv3(x, edge_index, edge_weight = edge_weight))\n",
    "        x = F.relu(self.conv4(x, edge_index, edge_weight = edge_weight))\n",
    "        x = F.relu(self.conv5(x, edge_index, edge_weight = edge_weight))\n",
    "        x = F.relu(self.conv6(x, edge_index, edge_weight = edge_weight))\n",
    "        x = self.conv7(x, edge_index, edge_weight = edge_weight)\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GC_GNN(\n",
       "  (conv1): GraphConv(8, 256)\n",
       "  (conv2): GraphConv(256, 256)\n",
       "  (conv3): GraphConv(256, 256)\n",
       "  (conv4): GraphConv(256, 256)\n",
       "  (conv5): GraphConv(256, 256)\n",
       "  (conv6): GraphConv(256, 256)\n",
       "  (conv7): GraphConv(256, 256)\n",
       "  (lin): Linear(256, 1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"models/gc_gnn_model.ckpt\"\n",
    "HIDDEN_CHANNELS = 256\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "model = GC_GNN(node_features_dim = dataset[0].x.shape[1], num_classes = 1, hidden_channels=HIDDEN_CHANNELS).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    sum_loss = 0\n",
    "    for data in loader: \n",
    "        data = data.to(device)\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch, edge_weight = data.edge_weight)  \n",
    "        \n",
    "        if  data.y.shape[0] == 1:\n",
    "            loss = torch.sqrt(criterion(torch.squeeze(out, 1), data.y))\n",
    "        else:\n",
    "            loss = torch.sqrt(criterion(torch.squeeze(out), data.y)) * data.y.shape[0]\n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "    return sum_loss / len(loader.dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out set RMSE with loaded model: 1.6386\n"
     ]
    }
   ],
   "source": [
    "hold_out_set_rmse = test(hold_out_loader)    \n",
    "print(f'Hold-out set RMSE with loaded model: {hold_out_set_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the predictions using EdgeSHAPer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1103,   77, 3258, ..., 1633, 3021, 1672])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_all_test_interactions = len(hold_out_data)\n",
    "all_test_interaction_indices = np.array(range(num_all_test_interactions))\n",
    "rng = np.random.default_rng(seed=SEED)\n",
    "rng.shuffle(all_test_interaction_indices)\n",
    "\n",
    "display(all_test_interaction_indices)\n",
    "\n",
    "SAMPLES_TO_EXPLAIN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1080a6a390d40b787287c799f2e40ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interaction: 6gfz\n",
      "No target class specified. Regression model assumed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [05:03<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving explanations visualization...\n",
      "\n",
      "Interaction: 1o4q\n",
      "No target class specified. Regression model assumed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [04:32<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving explanations visualization...\n",
      "\n",
      "Interaction: 5a3r\n",
      "No target class specified. Regression model assumed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 372/372 [08:44<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving explanations visualization...\n",
      "\n",
      "Interaction: 5nf5\n",
      "No target class specified. Regression model assumed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [03:34<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving explanations visualization...\n",
      "\n",
      "Interaction: 5oui\n",
      "No target class specified. Regression model assumed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [01:37<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving explanations visualization...\n",
      "Average number of important protein edges:  2.6\n",
      "Average number of important ligand edges:  9.2\n",
      "Average number of important interaction edges:  13.2\n"
     ]
    }
   ],
   "source": [
    "EDGE_WEIGHT = True\n",
    "TARGET_CLASS= None #regression problem\n",
    "TOP_K_EDGES = 25\n",
    "EXPLANATION_FOLDER = \"results/protein_ligand_affinity_explanations_edgeshaper/\"\n",
    "\n",
    "protein_edges_important = []\n",
    "ligand_edges_important = []\n",
    "interaction_edges_important = []\n",
    "\n",
    "for index in tqdm(all_test_interaction_indices[:SAMPLES_TO_EXPLAIN]):\n",
    "    model.eval()\n",
    "    test_interaction = hold_out_data[index]\n",
    "    print(\"\\nInteraction: \" + test_interaction.interaction_name)\n",
    "\n",
    "    edge_weight_to_pass = None\n",
    "    if EDGE_WEIGHT:\n",
    "        edge_weight_to_pass = test_interaction.edge_weight.to(device)\n",
    "\n",
    "    batch = torch.zeros(test_interaction.x.shape[0], dtype=int, device=test_interaction.x.device)\n",
    "    \n",
    "    \n",
    "    out = model(test_interaction.x.to(device), test_interaction.edge_index.to(device), batch=batch.to(device), edge_weight=edge_weight_to_pass)\n",
    "\n",
    "    edgeshaper_explainer = Edgeshaper(model, test_interaction.x, test_interaction.edge_index, edge_weight = test_interaction.edge_weight, device = device)\n",
    "\n",
    "    phi_edges = edgeshaper_explainer.explain(M = 100, target_class = TARGET_CLASS, seed = SEED) \n",
    "\n",
    "    SAVE_PATH = EXPLANATION_FOLDER + test_interaction.interaction_name + \"/\"\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(SAVE_PATH):\n",
    "        os.makedirs(SAVE_PATH)\n",
    "\n",
    "\n",
    "    with open(SAVE_PATH + test_interaction.interaction_name + \"_statistics.txt\", \"w+\") as f:\n",
    "        f.write(\"Interaction name: \" + test_interaction.interaction_name + \"\\n\\n\")\n",
    "        f.write(\"Affinity: \" + str(test_interaction.y.item()) + \"\\n\")\n",
    "        f.write(\"Predicted value: \" + str(out.item()) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "        f.write(\"Shapley values for edges: \\n\\n\")\n",
    "        for i in range(len(phi_edges)):\n",
    "            f.write(\"(\" + str(test_interaction.edge_index[0][i].item()) + \",\" + str(test_interaction.edge_index[1][i].item()) + \"): \" + str(phi_edges[i]) + \"\\n\\n\")\n",
    "\n",
    "    #plotting\n",
    "    print(\"Saving explanations visualization...\")\n",
    "\n",
    "    num_bonds = test_interaction.networkx_graph.number_of_edges()\n",
    "\n",
    "    rdkit_bonds_phi = [0]*num_bonds\n",
    "    rdkit_bonds = {}\n",
    "\n",
    "    bonds = dict(test_interaction.networkx_graph.edges())\n",
    "    bonds = list(bonds.keys())\n",
    "\n",
    "    for i in range(num_bonds):\n",
    "        init_atom = bonds[i][0]\n",
    "        end_atom = bonds[i][1]\n",
    "        \n",
    "        rdkit_bonds[(init_atom, end_atom)] = i\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(len(phi_edges)):\n",
    "        phi_value = phi_edges[i]\n",
    "        init_atom = test_interaction.edge_index[0][i].item()\n",
    "        end_atom = test_interaction.edge_index[1][i].item()\n",
    "        \n",
    "        if (init_atom, end_atom) in rdkit_bonds:\n",
    "            bond_index = rdkit_bonds[(init_atom, end_atom)]\n",
    "            rdkit_bonds_phi[bond_index] += phi_value\n",
    "        if (end_atom, init_atom) in rdkit_bonds:\n",
    "            bond_index = rdkit_bonds[(end_atom, init_atom)]\n",
    "            rdkit_bonds_phi[bond_index] += phi_value\n",
    "\n",
    "    G = test_interaction.networkx_graph\n",
    "    colors = [\"red\" if G.nodes[node][\"origin\"] == \"L\" else \"lightblue\" for node in G.nodes]\n",
    "\n",
    "    absolute_phi = np.abs(rdkit_bonds_phi)\n",
    "    #sort indices according to decreasing phi values\n",
    "    indices_sorted = np.argsort(-absolute_phi)\n",
    "\n",
    "    top_edges = indices_sorted[:TOP_K_EDGES]\n",
    "\n",
    "    atoms_origin = nx.get_node_attributes(G, 'origin')\n",
    "\n",
    "    edges_to_draw = []\n",
    "    edges_colors = []\n",
    "    edges_widths = []\n",
    "\n",
    "    num_protein_edges_important = 0\n",
    "    num_ligand_edges_important = 0\n",
    "    num_interaction_edges_important = 0\n",
    "    for bond in bonds:\n",
    "        init_atom = bond[0]\n",
    "        end_atom = bond[1]\n",
    "\n",
    "        bond_index = rdkit_bonds[(init_atom, end_atom)]\n",
    "        if bond_index in top_edges:\n",
    "            if atoms_origin[init_atom] == \"P\" and atoms_origin[end_atom] == \"P\":\n",
    "                num_protein_edges_important += 1\n",
    "                edges_colors.append(\"darkblue\")\n",
    "            elif atoms_origin[init_atom] == \"L\" and atoms_origin[end_atom] == \"L\":\n",
    "                num_ligand_edges_important += 1\n",
    "                edges_colors.append(\"darkred\")\n",
    "            else:\n",
    "                num_interaction_edges_important += 1\n",
    "                edges_colors.append(\"darkgreen\")\n",
    "            edges_widths.append(3)\n",
    "            \n",
    "        else:\n",
    "            edges_colors.append(\"lightgrey\") \n",
    "            edges_widths.append(1.5)\n",
    "\n",
    "    protein_edges_important.append(num_protein_edges_important)\n",
    "    ligand_edges_important.append(num_ligand_edges_important)\n",
    "    interaction_edges_important.append(num_interaction_edges_important)\n",
    "\n",
    "    with open(SAVE_PATH + test_interaction.interaction_name + \"_statistics.txt\", \"a+\") as f:\n",
    "        f.write(\"Number of important protein edges: \" + str(num_protein_edges_important) + \"\\n\")\n",
    "        f.write(\"Number of important ligand edges: \" + str(num_ligand_edges_important) + \"\\n\")\n",
    "        f.write(\"Number of important interaction edges: \" + str(num_interaction_edges_important) + \"\\n\")\n",
    "        \n",
    "    #draw graph with important edges\n",
    "    plt.figure(figsize=(10,10))\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    nx.draw(G, pos=pos, node_size = 400, with_labels=True, font_weight='bold', labels=nx.get_node_attributes(G, 'atom_type'), node_color=colors,edge_color=edges_colors, width=edges_widths)  \n",
    "\n",
    "    plt.savefig(SAVE_PATH + test_interaction.interaction_name + \"_EdgeSHAPer_top_\" + str(TOP_K_EDGES) + \"_edges.png\" , dpi=300)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    #save original interaction graph\n",
    "    plt.figure(figsize=(10,10))\n",
    "                    \n",
    "    nx.draw(G, pos=pos, node_size = 400, with_labels=True, font_weight='bold', labels=nx.get_node_attributes(G, 'atom_type'), node_color=colors)\n",
    "    \n",
    "    plt.savefig(SAVE_PATH + test_interaction.interaction_name + \"_interaction_graph.png\" , dpi=300)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nAverage number of important protein edges: \", np.mean(protein_edges_important))\n",
    "print(\"Average number of important ligand edges: \", np.mean(ligand_edges_important))\n",
    "print(\"Average number of important interaction edges: \", np.mean(interaction_edges_important))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN_XAI_Biomedicine_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
